{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_path = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download label mapping\n",
    "sentiment_labels = []\n",
    "sentiment_mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(sentiment_mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "sentiment_labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cardiffnlp/twitter-roberta-base-sentiment\\\\tokenizer_config.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment\\\\special_tokens_map.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment\\\\vocab.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment\\\\merges.txt',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment\\\\added_tokens.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    sentiment_model_path)\n",
    "sentiment_model.save_pretrained(sentiment_model_path)\n",
    "sentiment_tokenizer.save_pretrained(sentiment_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PHARMA_PATH = '../../data/twitter/extra data/pharma companies'\n",
    "GOVT_INSTITUTES_PATH = '../../data/twitter/extra data/public health agencies'\n",
    "NGO_PATH = '../../data/twitter/extra data/ngo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob.glob(PHARMA_PATH+'/*.csv'):\n",
    "#     user_df = pd.read_csv(file)\n",
    "#     username = user_df['username'].unique()[0]\n",
    "    \n",
    "#     for index, row in user_df.iterrows():\n",
    "#         tweet = row['tweet']\n",
    "#         tweet = preprocess(tweet)\n",
    "\n",
    "#         # Calculate sentiment\n",
    "#         sentiment_encoded_input = sentiment_tokenizer(\n",
    "#             tweet, return_tensors='pt')\n",
    "#         sentiment_output = sentiment_model(**sentiment_encoded_input)\n",
    "#         sentiment_scores = sentiment_output[0][0].detach().numpy()\n",
    "#         sentiment_scores = softmax(sentiment_scores)\n",
    "\n",
    "#         sentiment_ranking = np.argsort(sentiment_scores)\n",
    "#         sentiment_ranking = sentiment_ranking[::-1]\n",
    "#         # print(sentiment_labels[sentiment_ranking[0]])\n",
    "#         for i in range(sentiment_scores.shape[0]):\n",
    "#             sentiment_label = sentiment_labels[sentiment_ranking[i]]\n",
    "#             sentiment_score = sentiment_scores[sentiment_ranking[i]]\n",
    "#             # print(f'{sentiment_label} {np.round(float(sentiment_score), 4)}')\n",
    "#             user_df.at[index, sentiment_label] = np.round(\n",
    "#                 float(sentiment_score), 6)\n",
    "#         user_df.at[index, 'sentiment'] = sentiment_labels[sentiment_ranking[0]]\n",
    "    \n",
    "#     user_df.to_csv(username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(GOVT_INSTITUTES_PATH+'/*.csv'):\n",
    "    user_df = pd.read_csv(file)\n",
    "    username = user_df['username'].unique()[0]\n",
    "    \n",
    "    for index, row in user_df.iterrows():\n",
    "        tweet = row['tweet']\n",
    "        tweet = preprocess(tweet)\n",
    "\n",
    "        # Calculate sentiment\n",
    "        sentiment_encoded_input = sentiment_tokenizer(\n",
    "            tweet, return_tensors='pt')\n",
    "        sentiment_output = sentiment_model(**sentiment_encoded_input)\n",
    "        sentiment_scores = sentiment_output[0][0].detach().numpy()\n",
    "        sentiment_scores = softmax(sentiment_scores)\n",
    "\n",
    "        sentiment_ranking = np.argsort(sentiment_scores)\n",
    "        sentiment_ranking = sentiment_ranking[::-1]\n",
    "        # print(sentiment_labels[sentiment_ranking[0]])\n",
    "        for i in range(sentiment_scores.shape[0]):\n",
    "            sentiment_label = sentiment_labels[sentiment_ranking[i]]\n",
    "            sentiment_score = sentiment_scores[sentiment_ranking[i]]\n",
    "            # print(f'{sentiment_label} {np.round(float(sentiment_score), 4)}')\n",
    "            user_df.at[index, sentiment_label] = np.round(\n",
    "                float(sentiment_score), 6)\n",
    "        user_df.at[index, 'sentiment'] = sentiment_labels[sentiment_ranking[0]]\n",
    "    \n",
    "    user_df.to_csv(username+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob.glob(NGO_PATH+'/*.csv'):\n",
    "#     user_df = pd.read_csv(file)\n",
    "#     username = user_df['username'].unique()[0]\n",
    "    \n",
    "#     for index, row in user_df.iterrows():\n",
    "#         if(isinstance(row.tweet, float)):\n",
    "#             row.tweet = str(row.tweet)\n",
    "#         tweet = row['tweet']\n",
    "#         tweet = preprocess(tweet)\n",
    "\n",
    "#         # Calculate sentiment\n",
    "#         sentiment_encoded_input = sentiment_tokenizer(\n",
    "#             tweet, return_tensors='pt')\n",
    "#         sentiment_output = sentiment_model(**sentiment_encoded_input)\n",
    "#         sentiment_scores = sentiment_output[0][0].detach().numpy()\n",
    "#         sentiment_scores = softmax(sentiment_scores)\n",
    "\n",
    "#         sentiment_ranking = np.argsort(sentiment_scores)\n",
    "#         sentiment_ranking = sentiment_ranking[::-1]\n",
    "#         # print(sentiment_labels[sentiment_ranking[0]])\n",
    "#         for i in range(sentiment_scores.shape[0]):\n",
    "#             sentiment_label = sentiment_labels[sentiment_ranking[i]]\n",
    "#             sentiment_score = sentiment_scores[sentiment_ranking[i]]\n",
    "#             # print(f'{sentiment_label} {np.round(float(sentiment_score), 4)}')\n",
    "#             user_df.at[index, sentiment_label] = np.round(\n",
    "#                 float(sentiment_score), 6)\n",
    "#         user_df.at[index, 'sentiment'] = sentiment_labels[sentiment_ranking[0]]\n",
    "    \n",
    "#     user_df.to_csv(username+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
